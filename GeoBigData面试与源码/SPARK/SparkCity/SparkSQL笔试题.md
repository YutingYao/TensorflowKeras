## 题目1

有hdfs文件，文件每行的格式为作品ID，用户id，用户性别。请用一个spark任务实现以下功能：统计每个作品对应的用户（去重后）的性别分布。输出格式如下：作品ID，男性用户数量，女性用户数量

```scala
sc.textfile() .flatmap(.split(","))//分割成作品ID，用户id，用户性别
  .map(((_.1,_._2),1))//((作品id,用户性别),1)
  .reduceByKey(_+_)//((作品id,用户性别),n)
  .map(_._1._1,_._1._2,_._2)//(作品id,用户性别,n
```

## 题目2

如何使用Spark实现TopN的获取（描述思路或使用伪代码）？

- 方法1：

```s
        （1）按照 key 对数据进行聚合（groupByKey）

        （2）将 value 转换为数组，利用scala的sortBy或者sortWith进行排序（mapValues）

        注意：当数据量太大时，会导致OOM
```

- 方法2：
  
```s
        （1）取出所有的 key

        （2）对 key 进行迭代，每次取出一个 key 利用 spark 的排序算子进行排序
```

- 方法3：

```s
        （1）自定义分区器，按照 key 进行分区，使不同的 key 进到不同的分区

        （2）对每个分区运用 spark 的排序算子进行排序
```
